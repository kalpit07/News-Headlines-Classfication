{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE  CATEGORY\n",
       "0  Fed official says weak data caused by weather,...  Business\n",
       "1  Fed's Charles Plosser sees high bar for change...  Business\n",
       "2  US open: Stocks fall after Fed official hints ...  Business\n",
       "3  Fed risks falling 'behind the curve', Charles ...  Business\n",
       "4  Fed's Plosser: Nasty Weather Has Curbed Job Gr...  Business"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating pandas DataFrame\n",
    "df = pd.read_csv('News Headlines Dataset.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Business', 'Science & Technology', 'Entertainment', 'Health'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# News Categories\n",
    "pd.unique(df['CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headlines Tokenization\n",
    "\n",
    "# Importing Libraries\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "TOKENIZED_TITLES = []\n",
    "\n",
    "for headline in df['TITLE']:\n",
    "    TOKENIZED_TITLES.append(word_tokenize(headline.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fed', 'official', 'says', 'weak', 'data', 'caused', 'by', 'weather', ',', 'should', 'not', 'slow', 'taper']\n",
      "['fed', \"'s\", 'charles', 'plosser', 'sees', 'high', 'bar', 'for', 'change', 'in', 'pace', 'of', 'tapering']\n",
      "['us', 'open', ':', 'stocks', 'fall', 'after', 'fed', 'official', 'hints', 'at', 'accelerated', 'tapering']\n",
      "['fed', 'risks', 'falling', \"'behind\", 'the', 'curve', \"'\", ',', 'charles', 'plosser', 'says']\n",
      "['fed', \"'s\", 'plosser', ':', 'nasty', 'weather', 'has', 'curbed', 'job', 'growth']\n",
      "['plosser', ':', 'fed', 'may', 'have', 'to', 'accelerate', 'tapering', 'pace']\n",
      "['fed', \"'s\", 'plosser', ':', 'taper', 'pace', 'may', 'be', 'too', 'slow']\n",
      "['fed', \"'s\", 'plosser', 'expects', 'us', 'unemployment', 'to', 'fall', 'to', '6.2', '%', 'by', 'the', 'end', 'of', '2014']\n",
      "['us', 'jobs', 'growth', 'last', 'month', 'hit', 'by', 'weather', ':', 'fed', 'president', 'charles', 'plosser']\n",
      "['ecb', 'unlikely', 'to', 'end', 'sterilisation', 'of', 'smp', 'purchases', '-', 'traders']\n"
     ]
    }
   ],
   "source": [
    "# Headlines have been tokenized\n",
    "for title in TOKENIZED_TITLES[0:10]:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling TOKENIZED_TITLES\n",
    "\n",
    "# Required Library\n",
    "import pickle\n",
    "\n",
    "file = \"TOKENIZED_TITLES.pkl\"\n",
    "fileobj = open(file, 'wb')\n",
    "pickle.dump(TOKENIZED_TITLES, fileobj)\n",
    "fileobj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Fed', 'official', 'says', 'weak', 'data', 'caused', 'by', 'weather', ',', 'should', 'not', 'slow', 'taper'], ['Fed', \"'s\", 'Charles', 'Plosser', 'sees', 'high', 'bar', 'for', 'change', 'in', 'pace', 'of', 'tapering'], ['US', 'open', ':', 'Stocks', 'fall', 'after', 'Fed', 'official', 'hints', 'at', 'accelerated', 'tapering'], ['Fed', 'risks', 'falling', \"'behind\", 'the', 'curve', \"'\", ',', 'Charles', 'Plosser', 'says'], ['Fed', \"'s\", 'Plosser', ':', 'Nasty', 'Weather', 'Has', 'Curbed', 'Job', 'Growth']]\n"
     ]
    }
   ],
   "source": [
    "#file = \"TOKENIZED_TITLE.pkl\"\n",
    "#fileobj = open(file, 'rb')\n",
    "#a = pickle.load(fileobj)\n",
    "#fileobj.close()\n",
    "#print(a[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Abhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download 'stopwords' from nltk if using for the first time\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Words : \n",
      "{'some', 'those', 'here', 'isn', 'won', 'same', 'above', 'my', 'what', 'an', 'o', 'when', 'where', 'himself', 'its', 'but', 'then', 'had', \"needn't\", 'such', 'wasn', 'against', \"wouldn't\", \"hasn't\", 'whom', 'of', 'do', 'if', 'below', 'that', 'under', \"shan't\", 'so', 'her', 'because', 'having', 'each', 'these', 'down', 'herself', 'needn', 'few', 'no', 'between', 'hasn', 'it', 'very', 'at', 'can', 'are', 'a', 've', 'both', \"she's\", 'not', 'his', \"didn't\", 'me', \"should've\", 'in', 'how', 'own', 'doesn', 'myself', 'ain', 'their', 'll', 'ourselves', 'our', 'from', 'shouldn', \"won't\", \"doesn't\", 'is', 'theirs', 'now', 'was', 'until', 'which', 'has', 'they', 'and', 'nor', 'him', 'on', \"wasn't\", \"you'll\", 't', 'once', 'more', 'than', \"weren't\", 'i', 'be', 'by', 'were', 'd', 'didn', 'over', 'further', 'or', 'm', 's', 're', 'couldn', 'you', 'been', 'with', 'themselves', 'yours', 'this', \"hadn't\", 'aren', 'being', 'itself', 'weren', 'other', 'wouldn', 'doing', \"aren't\", 'am', 'just', 'she', 'there', \"that'll\", 'did', 'after', 'for', 'y', 'while', 'out', 'why', 'into', 'up', 'mightn', \"haven't\", 'yourselves', 'as', 'who', \"couldn't\", 'will', 'off', 'all', 'during', 'don', 'does', 'your', 'he', 'should', 'to', 'have', 'before', \"isn't\", \"shouldn't\", 'we', 'most', 'ma', 'any', 'them', 'hadn', 'too', 'about', \"it's\", 'shan', 'mustn', \"don't\", 'haven', \"mightn't\", 'hers', \"you've\", 'yourself', 'through', \"you'd\", 'the', 'again', \"mustn't\", 'only', 'ours', \"you're\"}\n",
      "\n",
      "Punctuations : \n",
      "{':', '>', '/', '&', '|', '^', '+', '-', '%', '`', ')', ',', '\\\\', '{', '\"', '$', '#', '=', '.', ';', '*', '?', '~', '}', '!', '[', '(', '_', '@', '<', ']', \"'\"}\n",
      "\n",
      "Filtered Titles : \n",
      "[['fed', 'official', 'says', 'weak', 'data', 'caused', 'weather', 'slow', 'taper'], ['fed', 'charles', 'plosser', 'sees', 'high', 'bar', 'change', 'pace', 'tapering'], ['us', 'open', 'stocks', 'fall', 'fed', 'official', 'hints', 'accelerated', 'tapering'], ['fed', 'risks', 'falling', \"'behind\", 'curve', 'charles', 'plosser', 'says'], ['fed', 'plosser', 'nasty', 'weather', 'curbed', 'job', 'growth']]\n"
     ]
    }
   ],
   "source": [
    "# Removal of Stop Words & Punctuation\n",
    "# Also removes 's\n",
    "\n",
    "# Required Libraries\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Stop Words for English Language\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "print(\"Stop Words : \")\n",
    "print(stop_words)\n",
    "\n",
    "# Punctuations\n",
    "punctuations = set(string.punctuation)\n",
    "print(\"\\nPunctuations : \")\n",
    "print(punctuations)\n",
    "\n",
    "# FILTERED TITLE =  Title Without Stop Words & Punctuations\n",
    "FILTERED_TITLES = []\n",
    "\n",
    "for title in TOKENIZED_TITLES:\n",
    "    temp_title = []\n",
    "    for word in title:\n",
    "        if((word not in stop_words) and (word not in punctuations) and (word != \"'s\")):\n",
    "            temp_title.append(word)\n",
    "            \n",
    "    FILTERED_TITLES.append(temp_title)\n",
    "        \n",
    "\n",
    "print(\"\\nFiltered Titles : \")\n",
    "print(FILTERED_TITLES[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling FILTERED_TITLES\n",
    "\n",
    "# Library already imported\n",
    "# import pickle\n",
    "\n",
    "file = \"FILTERED_TITLES.pkl\"\n",
    "fileobj = open(file, 'wb')\n",
    "pickle.dump(FILTERED_TITLES, fileobj)\n",
    "fileobj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Titles Headlines : \n",
      "['fed offici say weak data caus weather slow taper', 'fed charl plosser see high bar chang pace taper', 'us open stock fall fed offici hint acceler taper', \"fed risk fall 'behind curv charl plosser say\", 'fed plosser nasti weather curb job growth']\n"
     ]
    }
   ],
   "source": [
    "# Stemming using Porter Stemmer\n",
    "\n",
    "# Required Library\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "STEMMED_TITLES_HEADLINES = []\n",
    "\n",
    "for title in FILTERED_TITLES:\n",
    "    temp_title = []\n",
    "    for word in title:\n",
    "        temp_title.append(porter.stem(word))\n",
    "        \n",
    "    STEMMED_TITLES_HEADLINES.append(\" \".join(temp_title))\n",
    "    \n",
    "    \n",
    "print(\"Stemmed Titles Headlines : \")\n",
    "print(STEMMED_TITLES_HEADLINES[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling STEMMED_TITLES_HEADLINES\n",
    "\n",
    "# Library already imported\n",
    "# import pickle\n",
    "\n",
    "file = \"STEMMED_TITLES_HEADLINES.pkl\"\n",
    "fileobj = open(file, 'wb')\n",
    "pickle.dump(STEMMED_TITLES_HEADLINES, fileobj)\n",
    "fileobj.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
