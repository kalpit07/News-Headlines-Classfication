{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE  CATEGORY\n",
       "0  Fed official says weak data caused by weather,...  Business\n",
       "1  Fed's Charles Plosser sees high bar for change...  Business\n",
       "2  US open: Stocks fall after Fed official hints ...  Business\n",
       "3  Fed risks falling 'behind the curve', Charles ...  Business\n",
       "4  Fed's Plosser: Nasty Weather Has Curbed Job Gr...  Business"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating pandas DataFrame\n",
    "df = pd.read_csv('News Headlines Dataset.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Business', 'Science & Technology', 'Entertainment', 'Health'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# News Categories\n",
    "pd.unique(df['CATEGORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headlines Tokenization\n",
    "\n",
    "# Importing Libraries\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "TOKENIZED_TITLES = []\n",
    "\n",
    "for headline in df['TITLE']:\n",
    "    TOKENIZED_TITLES.append(word_tokenize(headline.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fed', 'official', 'says', 'weak', 'data', 'caused', 'by', 'weather', ',', 'should', 'not', 'slow', 'taper']\n",
      "['fed', \"'s\", 'charles', 'plosser', 'sees', 'high', 'bar', 'for', 'change', 'in', 'pace', 'of', 'tapering']\n",
      "['us', 'open', ':', 'stocks', 'fall', 'after', 'fed', 'official', 'hints', 'at', 'accelerated', 'tapering']\n",
      "['fed', 'risks', 'falling', \"'behind\", 'the', 'curve', \"'\", ',', 'charles', 'plosser', 'says']\n",
      "['fed', \"'s\", 'plosser', ':', 'nasty', 'weather', 'has', 'curbed', 'job', 'growth']\n",
      "['plosser', ':', 'fed', 'may', 'have', 'to', 'accelerate', 'tapering', 'pace']\n",
      "['fed', \"'s\", 'plosser', ':', 'taper', 'pace', 'may', 'be', 'too', 'slow']\n",
      "['fed', \"'s\", 'plosser', 'expects', 'us', 'unemployment', 'to', 'fall', 'to', '6.2', '%', 'by', 'the', 'end', 'of', '2014']\n",
      "['us', 'jobs', 'growth', 'last', 'month', 'hit', 'by', 'weather', ':', 'fed', 'president', 'charles', 'plosser']\n",
      "['ecb', 'unlikely', 'to', 'end', 'sterilisation', 'of', 'smp', 'purchases', '-', 'traders']\n"
     ]
    }
   ],
   "source": [
    "# Headlines have been tokenized\n",
    "for title in TOKENIZED_TITLES[0:10]:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling TOKENIZED_TITLES\n",
    "\n",
    "# Required Library\n",
    "import pickle\n",
    "\n",
    "file = \"TOKENIZED_TITLES.pkl\"\n",
    "fileobj = open(file, 'wb')\n",
    "pickle.dump(TOKENIZED_TITLES, fileobj)\n",
    "fileobj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Fed', 'official', 'says', 'weak', 'data', 'caused', 'by', 'weather', ',', 'should', 'not', 'slow', 'taper'], ['Fed', \"'s\", 'Charles', 'Plosser', 'sees', 'high', 'bar', 'for', 'change', 'in', 'pace', 'of', 'tapering'], ['US', 'open', ':', 'Stocks', 'fall', 'after', 'Fed', 'official', 'hints', 'at', 'accelerated', 'tapering'], ['Fed', 'risks', 'falling', \"'behind\", 'the', 'curve', \"'\", ',', 'Charles', 'Plosser', 'says'], ['Fed', \"'s\", 'Plosser', ':', 'Nasty', 'Weather', 'Has', 'Curbed', 'Job', 'Growth']]\n"
     ]
    }
   ],
   "source": [
    "#file = \"TOKENIZED_TITLE.pkl\"\n",
    "#fileobj = open(file, 'rb')\n",
    "#a = pickle.load(fileobj)\n",
    "#fileobj.close()\n",
    "#print(a[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Abhi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download 'stopwords' from nltk if using for the first time\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Words : \n",
      "{'some', 'those', 'here', 'isn', 'won', 'same', 'above', 'my', 'what', 'an', 'o', 'when', 'where', 'himself', 'its', 'but', 'then', 'had', \"needn't\", 'such', 'wasn', 'against', \"wouldn't\", \"hasn't\", 'whom', 'of', 'do', 'if', 'below', 'that', 'under', \"shan't\", 'so', 'her', 'because', 'having', 'each', 'these', 'down', 'herself', 'needn', 'few', 'no', 'between', 'hasn', 'it', 'very', 'at', 'can', 'are', 'a', 've', 'both', \"she's\", 'not', 'his', \"didn't\", 'me', \"should've\", 'in', 'how', 'own', 'doesn', 'myself', 'ain', 'their', 'll', 'ourselves', 'our', 'from', 'shouldn', \"won't\", \"doesn't\", 'is', 'theirs', 'now', 'was', 'until', 'which', 'has', 'they', 'and', 'nor', 'him', 'on', \"wasn't\", \"you'll\", 't', 'once', 'more', 'than', \"weren't\", 'i', 'be', 'by', 'were', 'd', 'didn', 'over', 'further', 'or', 'm', 's', 're', 'couldn', 'you', 'been', 'with', 'themselves', 'yours', 'this', \"hadn't\", 'aren', 'being', 'itself', 'weren', 'other', 'wouldn', 'doing', \"aren't\", 'am', 'just', 'she', 'there', \"that'll\", 'did', 'after', 'for', 'y', 'while', 'out', 'why', 'into', 'up', 'mightn', \"haven't\", 'yourselves', 'as', 'who', \"couldn't\", 'will', 'off', 'all', 'during', 'don', 'does', 'your', 'he', 'should', 'to', 'have', 'before', \"isn't\", \"shouldn't\", 'we', 'most', 'ma', 'any', 'them', 'hadn', 'too', 'about', \"it's\", 'shan', 'mustn', \"don't\", 'haven', \"mightn't\", 'hers', \"you've\", 'yourself', 'through', \"you'd\", 'the', 'again', \"mustn't\", 'only', 'ours', \"you're\"}\n",
      "\n",
      "Punctuations : \n",
      "{':', '>', '/', '&', '|', '^', '+', '-', '%', '`', ')', ',', '\\\\', '{', '\"', '$', '#', '=', '.', ';', '*', '?', '~', '}', '!', '[', '(', '_', '@', '<', ']', \"'\"}\n",
      "\n",
      "Filtered Titles : \n",
      "[['fed', 'official', 'says', 'weak', 'data', 'caused', 'weather', 'slow', 'taper'], ['fed', 'charles', 'plosser', 'sees', 'high', 'bar', 'change', 'pace', 'tapering'], ['us', 'open', 'stocks', 'fall', 'fed', 'official', 'hints', 'accelerated', 'tapering'], ['fed', 'risks', 'falling', \"'behind\", 'curve', 'charles', 'plosser', 'says'], ['fed', 'plosser', 'nasty', 'weather', 'curbed', 'job', 'growth']]\n"
     ]
    }
   ],
   "source": [
    "# Removal of Stop Words & Punctuation\n",
    "# Also removes 's\n",
    "\n",
    "# Required Libraries\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Stop Words for English Language\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "print(\"Stop Words : \")\n",
    "print(stop_words)\n",
    "\n",
    "# Punctuations\n",
    "punctuations = set(string.punctuation)\n",
    "print(\"\\nPunctuations : \")\n",
    "print(punctuations)\n",
    "\n",
    "# FILTERED TITLE =  Title Without Stop Words & Punctuations\n",
    "FILTERED_TITLES = []\n",
    "\n",
    "for title in TOKENIZED_TITLES:\n",
    "    temp_title = []\n",
    "    for word in title:\n",
    "        if((word not in stop_words) and (word not in punctuations) and (word != \"'s\")):\n",
    "            temp_title.append(word)\n",
    "            \n",
    "    FILTERED_TITLES.append(temp_title)\n",
    "        \n",
    "\n",
    "print(\"\\nFiltered Titles : \")\n",
    "print(FILTERED_TITLES[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling FILTERED_TITLES\n",
    "\n",
    "# Library already imported\n",
    "# import pickle\n",
    "\n",
    "file = \"FILTERED_TITLES.pkl\"\n",
    "fileobj = open(file, 'wb')\n",
    "pickle.dump(FILTERED_TITLES, fileobj)\n",
    "fileobj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Titles : \n",
      "[['fed', 'offici', 'say', 'weak', 'data', 'caus', 'weather', 'slow', 'taper'], ['fed', 'charl', 'plosser', 'see', 'high', 'bar', 'chang', 'pace', 'taper'], ['us', 'open', 'stock', 'fall', 'fed', 'offici', 'hint', 'acceler', 'taper'], ['fed', 'risk', 'fall', \"'behind\", 'curv', 'charl', 'plosser', 'say'], ['fed', 'plosser', 'nasti', 'weather', 'curb', 'job', 'growth']]\n"
     ]
    }
   ],
   "source": [
    "# Stemming using Porter Stemmer\n",
    "\n",
    "# Required Library\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "STEMMED_TITLES = []\n",
    "\n",
    "for title in FILTERED_TITLES:\n",
    "    temp_title = []\n",
    "    for word in title:\n",
    "        temp_title.append(porter.stem(word))\n",
    "        \n",
    "    STEMMED_TITLES.append(temp_title)\n",
    "    \n",
    "    \n",
    "print(\"Stemmed Titles : \")\n",
    "print(STEMMED_TITLES[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling STEMMED_TITLES\n",
    "\n",
    "# Library already imported\n",
    "# import pickle\n",
    "\n",
    "file = \"STEMMED_TITLES.pkl\"\n",
    "fileobj = open(file, 'wb')\n",
    "pickle.dump(STEMMED_TITLES, fileobj)\n",
    "fileobj.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
